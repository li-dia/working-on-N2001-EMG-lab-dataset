{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "2m-VDw7J1u4K"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import  keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,scale\n",
    "from skimage.measure import block_reduce\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "8Rwb_WUh105H"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"data\"].transpose()  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['data'].transpose() # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['data'].transpose() #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "lgHV-6wU12n5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_data_minmax(data):\n",
    "#type of scaler that scales the minimum and maximum values to be 0 and 1 respectively. \n",
    "    scaler = MinMaxScaler()\n",
    "#fit_transform() then it will calculate the mean(μ) and standard deviation(σ) of the feature F at a time it will transform the data points of the feature F.    \n",
    "    normalized_data =scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "bcIEKXLjciKr"
   },
   "outputs": [],
   "source": [
    "def scale_data_standard(data):\n",
    "    scaled_data = scale(data,axis=1)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "I_QR6IDs14Dm"
   },
   "outputs": [],
   "source": [
    "def gen_tensors_list(data,dim):\n",
    "    dataset  = list()\n",
    "    for i in range (len(data)):\n",
    "        arg = tf.convert_to_tensor(data[i], dtype=tf.float32)\n",
    "        arg = tf.reshape(arg,dim)\n",
    "        dataset.append(arg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "gaSw9KLt15zX"
   },
   "outputs": [],
   "source": [
    "def windowing_fun(data,window_size=1000,overlap=100):\n",
    "    windowed_data = [data[j][i : i + window_size] for j in range(0,len(data)) for i in range(0, len(data[j]), window_size-overlap)]\n",
    "    final_data = [windowed_data[i] for i in range(len(windowed_data)) if len(windowed_data[i]) == window_size ]\n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "zKAC9ocbn33R"
   },
   "outputs": [],
   "source": [
    "def load_file_names():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"files\"]  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['files'] # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['files'] #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "CEcbdDJD36Ro"
   },
   "outputs": [],
   "source": [
    "def generate_dataframe(data,files):\n",
    "    df = pd.DataFrame([], columns=['type_signal',\"num_personne\",\"muscle\",\"num_enregistrement\",\"signal\"])\n",
    "    windowed_data = [{\"signal\": data[j],\"type_signal\":files[0][j][0][5],\"num_personne\": files[0][j][0][6:8],\"muscle\": files[0][j][0][8:10],\"num_enregistrement\":files[0][j][0][10:12] } for j in range(0,len(data)) ]\n",
    "    final_data = pd.DataFrame(windowed_data)\n",
    "    #df =df.append(final_data, ignore_index=True)\n",
    "    #df =pd.concat([df, final_data])\n",
    "    df = pd.concat([df, final_data], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "22ZQdg5FViHH"
   },
   "outputs": [],
   "source": [
    "als, normal , myopathy = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "70ffS0nSn3u9"
   },
   "outputs": [],
   "source": [
    "alsfiles,normalfiles,myopathyfiles = load_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "m3v-unfnVKTq"
   },
   "outputs": [],
   "source": [
    "df = generate_dataframe(np.vstack((normal,als,myopathy)),np.concatenate((normalfiles,alsfiles,myopathyfiles),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "AgRS2F9AVvDq"
   },
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return {\"C\":0,\"A\":1,\"M\":2}[row[\"type_signal\"]]\n",
    "\n",
    "df[\"num_class\"] =df.apply(f, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "MoeHi_gvST3W"
   },
   "outputs": [],
   "source": [
    "df = df.query(\"muscle=='BB'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "4Zc_4AzmrQ3s"
   },
   "outputs": [],
   "source": [
    "X = df['signal'].tolist()\n",
    "Y = df['num_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "NYc4-mxsrLpm"
   },
   "outputs": [],
   "source": [
    "X=X[170:]\n",
    "Y=Y[170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "aH0VoR_UE3yR"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##WAVEFORM WRAP\n",
    "# Select a few random samples from your dataset\n",
    "samples = random.sample(list(X), k=3)\n",
    "\n",
    "def waveform_warp(signal, intensity):\n",
    "    t = np.arange(len(signal))\n",
    "    random_shift = np.random.uniform(-intensity, intensity)\n",
    "    warping_function = np.sin(t + random_shift)\n",
    "    warping_function = np.reshape(warping_function, (len(warping_function), 1))\n",
    "    warped_signal = signal * warping_function\n",
    "    return warped_signal\n",
    "\n",
    "# Plot the original and augmented signals\n",
    "for sample in samples:\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "    axs[0].plot(sample)\n",
    "    axs[0].set_title('Original Signal')\n",
    "    \n",
    "    # Apply augmentation techniques\n",
    "    X = np.array(X)\n",
    "    augmented_sample = waveform_warp(X, 2)\n",
    "    \n",
    "    \n",
    "    axs[1].plot(augmented_sample)\n",
    "    axs[1].set_title('Augmented Signal')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation using waveform wrap\n",
    "def waveform_warp(signal, intensity):\n",
    "    t = np.arange(len(signal))\n",
    "    random_shift = np.random.uniform(-intensity, intensity)\n",
    "    warping_function = np.sin(t + random_shift)\n",
    "    warping_function = np.reshape(warping_function, (len(warping_function), 1))\n",
    "    warped_signal = signal * warping_function\n",
    "    return warped_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_X = waveform_warp(X, 0.2)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "C0CR1uU2XRKo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [*augmented_X]\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(augmented_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [*X]\n",
    "#data = data + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 262134)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data = np.concatenate((data, augmented_X))\n",
    "np.shape(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "n-GIqksRfZRm"
   },
   "outputs": [],
   "source": [
    "del  als,normal,myopathy,alsfiles,normalfiles,myopathyfiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "Blrv7OFwUm4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 262134), (305, 262134))"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = augmented_data\n",
    "data = scale_data_standard(data)\n",
    "np.shape(data), np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 262134)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_normal = Y.count(0)\n",
    "last_index_normal = count_normal * 2 - 1\n",
    "last_index_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "dmru4zsF421H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_als = Y.count(1)\n",
    "last_index_als = last_index_normal + count_als * 2\n",
    "last_index_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "9tVZ_pi5421I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_myopathy = Y.count(2)\n",
    "last_index_myopathy = last_index_als + count_myopathy * 2\n",
    "last_index_myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 262134)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "id": "swCxixoS421I"
   },
   "outputs": [],
   "source": [
    "window_size = 10000\n",
    "overlap = 1000\n",
    "X_windowed = windowing_fun(X, window_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_normal = np.count_nonzero(Y == 0)\n",
    "count_als = np.count_nonzero(Y == 1)\n",
    "count_myopathy = np.count_nonzero(Y == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_windowed = [0]*count_normal + [1]*count_als + [2]*count_myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove excess windows for which the label is unknown\n",
    "num_samples = min(len(X_windowed), len(Y_windowed))\n",
    "X_windowed = X_windowed[:num_samples]\n",
    "Y_windowed = Y_windowed[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_windowed = np.array(X_windowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and labels in unison\n",
    "rng = np.random.default_rng()\n",
    "indices = rng.permutation(num_samples)\n",
    "X_windowed = X_windowed[indices]\n",
    "Y_windowed = np.array(Y_windowed)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305,)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "r_VgwyYfYWnt"
   },
   "outputs": [],
   "source": [
    "X = windowing_fun(data,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15860, 10000)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "BpKYgn3EkgsU"
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "id": "3B8PeUZaeeQC"
   },
   "outputs": [],
   "source": [
    "X = scale_data_standard(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "Q1h0Nh9nlim8"
   },
   "outputs": [],
   "source": [
    "tensors_list = gen_tensors_list(X,(1,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "id": "LAQNPWwyHK7g"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [15860, 305]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [299]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#X_train, X_test, y_train, y_test = train_test_split( tensors_list, Y, test_size=0.04,random_state=20)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mshape(X_train), np\u001b[38;5;241m.\u001b[39mshape(X_val)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2417\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2417\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2419\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2420\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2421\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2422\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:378\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 378\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15860, 305]"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split( tensors_list, Y, test_size=0.04,random_state=20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(tensors_list, Y, test_size=0.2, random_state=42)\n",
    "np.shape(X_train), np.shape(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Conv2D(#of filters, filters size, activation function)\n",
    "    #in keras for the first layer we always need to mention the input shape\n",
    "    Conv1D(64, 5, activation = 'relu', padding =\"same\", input_shape = (1,262134)), \n",
    "    \n",
    "    #MaxPooling2D(filter size stride and pad can also be added)\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #LAYER2\n",
    "    Conv1D(32, 5, activation = 'relu', padding =\"same\"), #inc filter size and stride\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #FLATTEN\n",
    "    Flatten(),\n",
    "    \n",
    "    #FC Layers:\n",
    "    \n",
    "    #LAYER3\n",
    "    #Dense : fully connected  Dense(#neurons, activation function )\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    #LAYER4\n",
    "    Dense(3, activation = 'softmax'),\n",
    "    \n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, epochs =20, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4/4 [==============================] - 50s 10s/step - loss: 0.2046 - accuracy: 0.9385 - val_loss: 3.1770 - val_accuracy: 0.4426\n",
      "Epoch 2/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.4820 - accuracy: 0.9221 - val_loss: 3.1391 - val_accuracy: 0.3934\n",
      "Epoch 3/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.4654 - accuracy: 0.9385 - val_loss: 3.0389 - val_accuracy: 0.3934\n",
      "Epoch 4/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.3414 - accuracy: 0.9426 - val_loss: 3.1063 - val_accuracy: 0.3770\n",
      "Epoch 5/60\n",
      "4/4 [==============================] - 48s 13s/step - loss: 0.4652 - accuracy: 0.9098 - val_loss: 3.0406 - val_accuracy: 0.3770\n",
      "Epoch 6/60\n",
      "4/4 [==============================] - 50s 12s/step - loss: 0.4160 - accuracy: 0.9139 - val_loss: 3.3405 - val_accuracy: 0.3770\n",
      "Epoch 7/60\n",
      "4/4 [==============================] - 43s 11s/step - loss: 0.5772 - accuracy: 0.9344 - val_loss: 3.4730 - val_accuracy: 0.3770\n",
      "Epoch 8/60\n",
      "4/4 [==============================] - 42s 10s/step - loss: 0.7022 - accuracy: 0.9057 - val_loss: 4.7391 - val_accuracy: 0.3607\n",
      "Epoch 9/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.2317 - accuracy: 0.9385 - val_loss: 5.7008 - val_accuracy: 0.3279\n",
      "Epoch 10/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.7077 - accuracy: 0.9098 - val_loss: 5.3472 - val_accuracy: 0.3770\n",
      "Epoch 11/60\n",
      "4/4 [==============================] - 46s 11s/step - loss: 0.4100 - accuracy: 0.9344 - val_loss: 3.8544 - val_accuracy: 0.3934\n",
      "Epoch 12/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.4277 - accuracy: 0.9262 - val_loss: 3.6381 - val_accuracy: 0.3934\n",
      "Epoch 13/60\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.4996 - accuracy: 0.9303 - val_loss: 3.5850 - val_accuracy: 0.4262\n",
      "Epoch 14/60\n",
      "4/4 [==============================] - 55s 13s/step - loss: 0.3042 - accuracy: 0.9549 - val_loss: 3.3502 - val_accuracy: 0.4426\n",
      "Epoch 15/60\n",
      "4/4 [==============================] - 53s 14s/step - loss: 0.5197 - accuracy: 0.9344 - val_loss: 3.9323 - val_accuracy: 0.3934\n",
      "Epoch 16/60\n",
      "4/4 [==============================] - 45s 11s/step - loss: 0.1637 - accuracy: 0.9467 - val_loss: 4.4398 - val_accuracy: 0.3607\n",
      "Epoch 17/60\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.1524 - accuracy: 0.9385 - val_loss: 4.5658 - val_accuracy: 0.3770\n",
      "Epoch 18/60\n",
      "4/4 [==============================] - 45s 11s/step - loss: 0.3661 - accuracy: 0.9467 - val_loss: 4.8244 - val_accuracy: 0.4098\n",
      "Epoch 19/60\n",
      "4/4 [==============================] - 48s 12s/step - loss: 0.2504 - accuracy: 0.9467 - val_loss: 5.3260 - val_accuracy: 0.3934\n",
      "Epoch 20/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.2881 - accuracy: 0.9426 - val_loss: 5.5614 - val_accuracy: 0.3770\n",
      "Epoch 21/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1820 - accuracy: 0.9795 - val_loss: 5.3579 - val_accuracy: 0.3443\n",
      "Epoch 22/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1324 - accuracy: 0.9590 - val_loss: 4.9196 - val_accuracy: 0.3443\n",
      "Epoch 23/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0493 - accuracy: 0.9713 - val_loss: 4.6387 - val_accuracy: 0.3443\n",
      "Epoch 24/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0532 - accuracy: 0.9672 - val_loss: 4.4808 - val_accuracy: 0.3607\n",
      "Epoch 25/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.9798 - accuracy: 0.9344 - val_loss: 4.3364 - val_accuracy: 0.4098\n",
      "Epoch 26/60\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.1223 - accuracy: 0.9467 - val_loss: 4.5245 - val_accuracy: 0.4098\n",
      "Epoch 27/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1965 - accuracy: 0.9672 - val_loss: 4.2276 - val_accuracy: 0.4590\n",
      "Epoch 28/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1490 - accuracy: 0.9508 - val_loss: 4.1796 - val_accuracy: 0.4426\n",
      "Epoch 29/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1679 - accuracy: 0.9631 - val_loss: 4.2296 - val_accuracy: 0.4262\n",
      "Epoch 30/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.2365 - accuracy: 0.9590 - val_loss: 4.1043 - val_accuracy: 0.3934\n",
      "Epoch 31/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0967 - accuracy: 0.9631 - val_loss: 3.8290 - val_accuracy: 0.4098\n",
      "Epoch 32/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0480 - accuracy: 0.9795 - val_loss: 5.0951 - val_accuracy: 0.4098\n",
      "Epoch 33/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0520 - accuracy: 0.9754 - val_loss: 5.7095 - val_accuracy: 0.3934\n",
      "Epoch 34/60\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.2665 - accuracy: 0.9467 - val_loss: 5.7949 - val_accuracy: 0.4426\n",
      "Epoch 35/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1198 - accuracy: 0.9631 - val_loss: 5.9012 - val_accuracy: 0.4590\n",
      "Epoch 36/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0608 - accuracy: 0.9713 - val_loss: 6.0173 - val_accuracy: 0.4262\n",
      "Epoch 37/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.2780 - accuracy: 0.9672 - val_loss: 5.8081 - val_accuracy: 0.4590\n",
      "Epoch 38/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1717 - accuracy: 0.9590 - val_loss: 6.6676 - val_accuracy: 0.4590\n",
      "Epoch 39/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0569 - accuracy: 0.9672 - val_loss: 9.6704 - val_accuracy: 0.4098\n",
      "Epoch 40/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0793 - accuracy: 0.9631 - val_loss: 11.6954 - val_accuracy: 0.4098\n",
      "Epoch 41/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0653 - accuracy: 0.9672 - val_loss: 10.5857 - val_accuracy: 0.3934\n",
      "Epoch 42/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1287 - accuracy: 0.9631 - val_loss: 8.4441 - val_accuracy: 0.4098\n",
      "Epoch 43/60\n",
      "4/4 [==============================] - 731s 11s/step - loss: 0.4307 - accuracy: 0.9508 - val_loss: 7.0672 - val_accuracy: 0.4098\n",
      "Epoch 44/60\n",
      "4/4 [==============================] - 35s 9s/step - loss: 0.0546 - accuracy: 0.9672 - val_loss: 6.5027 - val_accuracy: 0.4262\n",
      "Epoch 45/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1411 - accuracy: 0.9672 - val_loss: 6.2388 - val_accuracy: 0.4262\n",
      "Epoch 46/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [303]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m X_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_val)\n\u001b[0;32m      4\u001b[0m y_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_val)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "history = model.fit(\n",
    "                    X_train, \n",
    "                    y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    validation_split=0.1,\n",
    "                    epochs=60, \n",
    "                    batch_size=64)\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(np.asarray(X_val),np.asarray (y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "jQl97_0NpBXX"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "53pvhyxLpwia"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D_score.json', 'w+') as file:\n",
    "\n",
    "    json.dump(score, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jFSDYnlvIrnb"
   },
   "outputs": [],
   "source": [
    "model= tf.keras.models.load_model(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in np.argmax(y_pred,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 3), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m con_mat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mconfusion_matrix(labels\u001b[38;5;241m=\u001b[39my_test, predictions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y_pred,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m con_mat_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(con_mat\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m con_mat\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis], decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m con_mat_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon_mat_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m figure \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(con_mat_df, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3, 3), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=np.argmax(y_pred,axis=1)).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = [\"Normal\",\"Neuropathie\"], \n",
    "                     columns = [\"Normal\",\"Neuropathie\"])\n",
    "\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
