{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2m-VDw7J1u4K"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import  keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,scale\n",
    "from skimage.measure import block_reduce\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8Rwb_WUh105H"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"data\"].transpose()  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['data'].transpose() # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['data'].transpose() #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lgHV-6wU12n5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_data_minmax(data):\n",
    "#type of scaler that scales the minimum and maximum values to be 0 and 1 respectively. \n",
    "    scaler = MinMaxScaler()\n",
    "#fit_transform() then it will calculate the mean(μ) and standard deviation(σ) of the feature F at a time it will transform the data points of the feature F.    \n",
    "    normalized_data =scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bcIEKXLjciKr"
   },
   "outputs": [],
   "source": [
    "def scale_data_standard(data):\n",
    "    scaled_data = scale(data,axis=1)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "I_QR6IDs14Dm"
   },
   "outputs": [],
   "source": [
    "def gen_tensors_list(data,dim):\n",
    "    dataset  = list()\n",
    "    for i in range (len(data)):\n",
    "        arg = tf.convert_to_tensor(data[i], dtype=tf.float32)\n",
    "        arg = tf.reshape(arg,dim)\n",
    "        dataset.append(arg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "gaSw9KLt15zX"
   },
   "outputs": [],
   "source": [
    "def windowing_fun(data,window_size=1000,overlap=100):\n",
    "    windowed_data = [data[j][i : i + window_size] for j in range(0,len(data)) for i in range(0, len(data[j]), window_size-overlap)]\n",
    "    final_data = [windowed_data[i] for i in range(len(windowed_data)) if len(windowed_data[i]) == window_size ]\n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zKAC9ocbn33R"
   },
   "outputs": [],
   "source": [
    "def load_file_names():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"files\"]  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['files'] # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['files'] #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CEcbdDJD36Ro"
   },
   "outputs": [],
   "source": [
    "def generate_dataframe(data,files):\n",
    "    df = pd.DataFrame([], columns=['type_signal',\"num_personne\",\"muscle\",\"num_enregistrement\",\"signal\"])\n",
    "    windowed_data = [{\"signal\": data[j],\"type_signal\":files[0][j][0][5],\"num_personne\": files[0][j][0][6:8],\"muscle\": files[0][j][0][8:10],\"num_enregistrement\":files[0][j][0][10:12] } for j in range(0,len(data)) ]\n",
    "    final_data = pd.DataFrame(windowed_data)\n",
    "    #df =df.append(final_data, ignore_index=True)\n",
    "    #df =pd.concat([df, final_data])\n",
    "    df = pd.concat([df, final_data], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "22ZQdg5FViHH"
   },
   "outputs": [],
   "source": [
    "als, normal , myopathy = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "70ffS0nSn3u9"
   },
   "outputs": [],
   "source": [
    "alsfiles,normalfiles,myopathyfiles = load_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "m3v-unfnVKTq"
   },
   "outputs": [],
   "source": [
    "df = generate_dataframe(np.vstack((normal,als,myopathy)),np.concatenate((normalfiles,alsfiles,myopathyfiles),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "AgRS2F9AVvDq"
   },
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return {\"C\":0,\"A\":1,\"M\":2}[row[\"type_signal\"]]\n",
    "\n",
    "df[\"num_class\"] =df.apply(f, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "MoeHi_gvST3W"
   },
   "outputs": [],
   "source": [
    "df = df.query(\"muscle=='BB'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "4Zc_4AzmrQ3s"
   },
   "outputs": [],
   "source": [
    "X = df['signal'].tolist()\n",
    "Y = df['num_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "NYc4-mxsrLpm"
   },
   "outputs": [],
   "source": [
    "X=X[170:]\n",
    "Y=Y[170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "aH0VoR_UE3yR"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##WAVEFORM WRAP\n",
    "# Select a few random samples from your dataset\n",
    "samples = random.sample(list(X), k=3)\n",
    "\n",
    "def waveform_warp(signal, intensity):\n",
    "    t = np.arange(len(signal))\n",
    "    random_shift = np.random.uniform(-intensity, intensity)\n",
    "    warping_function = np.sin(t + random_shift)\n",
    "    warping_function = np.reshape(warping_function, (len(warping_function), 1))\n",
    "    warped_signal = signal * warping_function\n",
    "    return warped_signal\n",
    "\n",
    "# Plot the original and augmented signals\n",
    "for sample in samples:\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "    axs[0].plot(sample)\n",
    "    axs[0].set_title('Original Signal')\n",
    "    \n",
    "    # Apply augmentation techniques\n",
    "    X = np.array(X)\n",
    "    augmented_sample = waveform_warp(X, 2)\n",
    "    \n",
    "    \n",
    "    axs[1].plot(augmented_sample)\n",
    "    axs[1].set_title('Augmented Signal')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation using waveform wrap\n",
    "def waveform_warp(signal, intensity):\n",
    "    t = np.arange(len(signal))\n",
    "    random_shift = np.random.uniform(-intensity, intensity)\n",
    "    warping_function = np.sin(t + random_shift)\n",
    "    warping_function = np.reshape(warping_function, (len(warping_function), 1))\n",
    "    warped_signal = signal * warping_function\n",
    "    return warped_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_X = waveform_warp(X, 2)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "C0CR1uU2XRKo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [*augmented_X]\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(augmented_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [*X]\n",
    "#data = data + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 262134)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data = np.concatenate((data, augmented_X))\n",
    "np.shape(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "n-GIqksRfZRm"
   },
   "outputs": [],
   "source": [
    "del  als,normal,myopathy,alsfiles,normalfiles,myopathyfiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "Blrv7OFwUm4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 262134), (305, 262134))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = augmented_data\n",
    "data = scale_data_standard(data)\n",
    "np.shape(data), np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 262134)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_normal = Y.count(0)\n",
    "last_index_normal = count_normal * 2 - 1\n",
    "last_index_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "dmru4zsF421H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_als = Y.count(1)\n",
    "last_index_als = last_index_normal + count_als * 2\n",
    "last_index_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "9tVZ_pi5421I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_myopathy = Y.count(2)\n",
    "last_index_myopathy = last_index_als + count_myopathy * 2\n",
    "last_index_myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "swCxixoS421I"
   },
   "outputs": [],
   "source": [
    "window_size = 10000\n",
    "overlap = 1000\n",
    "X_windowed = windowing_fun(X, window_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_normal = np.count_nonzero(Y == 0)\n",
    "count_als = np.count_nonzero(Y == 1)\n",
    "count_myopathy = np.count_nonzero(Y == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_windowed = [0]*count_normal + [1]*count_als + [2]*count_myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove excess windows for which the label is unknown\n",
    "num_samples = min(len(X_windowed), len(Y_windowed))\n",
    "X_windowed = X_windowed[:num_samples]\n",
    "Y_windowed = Y_windowed[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_windowed = np.array(X_windowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and labels in unison\n",
    "rng = np.random.default_rng()\n",
    "indices = rng.permutation(num_samples)\n",
    "X_windowed = X_windowed[indices]\n",
    "Y_windowed = np.array(Y_windowed)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "r_VgwyYfYWnt"
   },
   "outputs": [],
   "source": [
    "X = windowing_fun(data,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 262134)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "BpKYgn3EkgsU"
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "3B8PeUZaeeQC"
   },
   "outputs": [],
   "source": [
    "X = scale_data_standard(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "Q1h0Nh9nlim8"
   },
   "outputs": [],
   "source": [
    "tensors_list = gen_tensors_list(X,(1,262134))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "LAQNPWwyHK7g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((244, 1, 262134), (61, 1, 262134))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split( tensors_list, Y, test_size=0.04,random_state=20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(tensors_list, Y, test_size=0.2, random_state=42)\n",
    "np.shape(X_train), np.shape(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Conv2D(#of filters, filters size, activation function)\n",
    "    #in keras for the first layer we always need to mention the input shape\n",
    "    Conv1D(64, 5, activation = 'relu', padding =\"same\", input_shape = (1,262134)), \n",
    "    \n",
    "    #MaxPooling2D(filter size stride and pad can also be added)\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #LAYER2\n",
    "    Conv1D(32, 5, activation = 'relu', padding =\"same\"), #inc filter size and stride\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #FLATTEN\n",
    "    Flatten(),\n",
    "    \n",
    "    #FC Layers:\n",
    "    \n",
    "    #LAYER3\n",
    "    #Dense : fully connected  Dense(#neurons, activation function )\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    #LAYER4\n",
    "    Dense(3, activation = 'softmax'),\n",
    "    \n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, epochs =20, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4/4 [==============================] - 45s 11s/step - loss: 1.7186 - accuracy: 0.7910 - val_loss: 3.1445 - val_accuracy: 0.4098\n",
      "Epoch 2/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 1.3471 - accuracy: 0.8320 - val_loss: 3.0537 - val_accuracy: 0.3770\n",
      "Epoch 3/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 1.3623 - accuracy: 0.7746 - val_loss: 3.0406 - val_accuracy: 0.3607\n",
      "Epoch 4/60\n",
      "4/4 [==============================] - 43s 11s/step - loss: 1.3106 - accuracy: 0.8115 - val_loss: 2.9507 - val_accuracy: 0.3607\n",
      "Epoch 5/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 1.4417 - accuracy: 0.8156 - val_loss: 2.7842 - val_accuracy: 0.3607\n",
      "Epoch 6/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.9262 - accuracy: 0.8648 - val_loss: 2.7406 - val_accuracy: 0.3770\n",
      "Epoch 7/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 1.2296 - accuracy: 0.8607 - val_loss: 2.6717 - val_accuracy: 0.3770\n",
      "Epoch 8/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.6732 - accuracy: 0.8525 - val_loss: 2.5856 - val_accuracy: 0.3607\n",
      "Epoch 9/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.8310 - accuracy: 0.8607 - val_loss: 2.5909 - val_accuracy: 0.3770\n",
      "Epoch 10/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.6880 - accuracy: 0.8852 - val_loss: 2.6440 - val_accuracy: 0.3770\n",
      "Epoch 11/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.5822 - accuracy: 0.8934 - val_loss: 2.7106 - val_accuracy: 0.4262\n",
      "Epoch 12/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.7478 - accuracy: 0.9057 - val_loss: 2.7255 - val_accuracy: 0.4098\n",
      "Epoch 13/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.7256 - accuracy: 0.8648 - val_loss: 2.8590 - val_accuracy: 0.4098\n",
      "Epoch 14/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.7418 - accuracy: 0.8811 - val_loss: 3.0446 - val_accuracy: 0.4262\n",
      "Epoch 15/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.5889 - accuracy: 0.8811 - val_loss: 3.0697 - val_accuracy: 0.4098\n",
      "Epoch 16/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.6352 - accuracy: 0.8811 - val_loss: 3.0451 - val_accuracy: 0.4426\n",
      "Epoch 17/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.7429 - accuracy: 0.8975 - val_loss: 2.9922 - val_accuracy: 0.4262\n",
      "Epoch 18/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.3131 - accuracy: 0.9180 - val_loss: 3.0247 - val_accuracy: 0.3934\n",
      "Epoch 19/60\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.2586 - accuracy: 0.9139 - val_loss: 3.0432 - val_accuracy: 0.3934\n",
      "Epoch 20/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.2873 - accuracy: 0.9221 - val_loss: 3.0500 - val_accuracy: 0.4098\n",
      "Epoch 21/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.5406 - accuracy: 0.9262 - val_loss: 3.0392 - val_accuracy: 0.4098\n",
      "Epoch 22/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.4832 - accuracy: 0.9180 - val_loss: 3.0979 - val_accuracy: 0.3934\n",
      "Epoch 23/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.5147 - accuracy: 0.9098 - val_loss: 3.2885 - val_accuracy: 0.4098\n",
      "Epoch 24/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.3526 - accuracy: 0.9098 - val_loss: 3.4317 - val_accuracy: 0.4262\n",
      "Epoch 25/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.3660 - accuracy: 0.8975 - val_loss: 3.5186 - val_accuracy: 0.4426\n",
      "Epoch 26/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.2431 - accuracy: 0.9426 - val_loss: 3.5657 - val_accuracy: 0.4262\n",
      "Epoch 27/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.2009 - accuracy: 0.9303 - val_loss: 3.6201 - val_accuracy: 0.4426\n",
      "Epoch 28/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.3552 - accuracy: 0.9262 - val_loss: 3.5717 - val_accuracy: 0.4590\n",
      "Epoch 29/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.3401 - accuracy: 0.9262 - val_loss: 3.5087 - val_accuracy: 0.4590\n",
      "Epoch 30/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.3368 - accuracy: 0.9180 - val_loss: 3.4665 - val_accuracy: 0.4426\n",
      "Epoch 31/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.4918 - accuracy: 0.9016 - val_loss: 3.4504 - val_accuracy: 0.4426\n",
      "Epoch 32/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.2634 - accuracy: 0.9139 - val_loss: 3.4420 - val_accuracy: 0.4262\n",
      "Epoch 33/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.2733 - accuracy: 0.9303 - val_loss: 3.4308 - val_accuracy: 0.4262\n",
      "Epoch 34/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.2978 - accuracy: 0.9221 - val_loss: 3.4214 - val_accuracy: 0.4098\n",
      "Epoch 35/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.2890 - accuracy: 0.9221 - val_loss: 3.3915 - val_accuracy: 0.4262\n",
      "Epoch 36/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.1044 - accuracy: 0.9590 - val_loss: 3.3598 - val_accuracy: 0.4098\n",
      "Epoch 37/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1687 - accuracy: 0.9508 - val_loss: 3.3367 - val_accuracy: 0.4098\n",
      "Epoch 38/60\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.4278 - accuracy: 0.9303 - val_loss: 3.3525 - val_accuracy: 0.4262\n",
      "Epoch 39/60\n",
      "4/4 [==============================] - 42s 11s/step - loss: 0.2590 - accuracy: 0.9549 - val_loss: 3.3813 - val_accuracy: 0.4098\n",
      "Epoch 40/60\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.3479 - accuracy: 0.9262 - val_loss: 3.3764 - val_accuracy: 0.4262\n",
      "Epoch 41/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.4176 - accuracy: 0.9262 - val_loss: 3.3543 - val_accuracy: 0.4262\n",
      "Epoch 42/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1751 - accuracy: 0.9385 - val_loss: 3.3419 - val_accuracy: 0.4262\n",
      "Epoch 43/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1721 - accuracy: 0.9344 - val_loss: 3.3418 - val_accuracy: 0.4262\n",
      "Epoch 44/60\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.1571 - accuracy: 0.9426 - val_loss: 3.3418 - val_accuracy: 0.4262\n",
      "Epoch 45/60\n",
      "1/4 [======>.......................] - ETA: 30s - loss: 0.0704 - accuracy: 0.9844"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "history = model.fit(\n",
    "                    X_train, \n",
    "                    y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    validation_split=0.1,\n",
    "                    epochs=60, \n",
    "                    batch_size=64)\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(np.asarray(X_val),np.asarray (y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "jQl97_0NpBXX"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "53pvhyxLpwia"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D_score.json', 'w+') as file:\n",
    "\n",
    "    json.dump(score, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jFSDYnlvIrnb"
   },
   "outputs": [],
   "source": [
    "model= tf.keras.models.load_model(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in np.argmax(y_pred,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 3), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m con_mat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mconfusion_matrix(labels\u001b[38;5;241m=\u001b[39my_test, predictions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y_pred,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m con_mat_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(con_mat\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m con_mat\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis], decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m con_mat_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon_mat_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m figure \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(con_mat_df, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3, 3), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=np.argmax(y_pred,axis=1)).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = [\"Normal\",\"Neuropathie\"], \n",
    "                     columns = [\"Normal\",\"Neuropathie\"])\n",
    "\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
