{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2m-VDw7J1u4K"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import  keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,scale\n",
    "from skimage.measure import block_reduce\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8Rwb_WUh105H"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"data\"].transpose()  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['data'].transpose() # (262134, 270) \n",
    "    myopathie = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['data'].transpose() #(262134, 315)\n",
    "    return als,normal,myopathie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lgHV-6wU12n5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_data_minmax(data):\n",
    "#type of scaler that scales the minimum and maximum values to be 0 and 1 respectively. \n",
    "    scaler = MinMaxScaler()\n",
    "#fit_transform() then it will calculate the mean(μ) and standard deviation(σ) of the feature F at a time it will transform the data points of the feature F.    \n",
    "    normalized_data =scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bcIEKXLjciKr"
   },
   "outputs": [],
   "source": [
    "def scale_data_standard(data):\n",
    "    scaled_data = scale(data,axis=1)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I_QR6IDs14Dm"
   },
   "outputs": [],
   "source": [
    "def gen_tensors_list(data,dim):\n",
    "    dataset  = list()\n",
    "    for i in range (len(data)):\n",
    "        arg = tf.convert_to_tensor(data[i], dtype=tf.float32)\n",
    "        arg = tf.reshape(arg,dim)\n",
    "        dataset.append(arg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gaSw9KLt15zX"
   },
   "outputs": [],
   "source": [
    "def windowing_fun(data,window_size=1000,overlap=100):\n",
    "    windowed_data = [data[j][i : i + window_size] for j in range(0,len(data)) for i in range(0, len(data[j]), window_size-overlap)]\n",
    "    final_data = [windowed_data[i] for i in range(len(windowed_data)) if len(windowed_data[i]) == window_size ]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zKAC9ocbn33R"
   },
   "outputs": [],
   "source": [
    "def load_file_names():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"files\"]  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['files'] # (262134, 270) \n",
    "    myopathie = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['files'] #(262134, 315)\n",
    "    return als,normal,myopathie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CEcbdDJD36Ro"
   },
   "outputs": [],
   "source": [
    "def generate_dataframe(data,files):\n",
    "    df = pd.DataFrame([], columns=['type_signal',\"num_personne\",\"muscle\",\"num_enregistrement\",\"signal\"])\n",
    "    windowed_data = [{\"signal\": data[j],\"type_signal\":files[0][j][0][5],\"num_personne\": files[0][j][0][6:8],\"muscle\": files[0][j][0][8:10],\"num_enregistrement\":files[0][j][0][10:12] } for j in range(0,len(data)) ]\n",
    "    final_data = [windowed_data[i] for i in range(len(windowed_data))]\n",
    "    df =df.append(final_data, ignore_index=True)\n",
    "    #df =pd.concat([df, final_data])\n",
    "    #df = pd.concat([df, pd.DataFrame.from_records(final_data)], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "22ZQdg5FViHH"
   },
   "outputs": [],
   "source": [
    "als, normal , myopathie = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "70ffS0nSn3u9"
   },
   "outputs": [],
   "source": [
    "alsfiles,normalfiles,myopathiefiles = load_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "m3v-unfnVKTq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_5984\\1494603022.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df =df.append(final_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = generate_dataframe(np.vstack((normal,als,myopathie)),np.concatenate((normalfiles,alsfiles,myopathiefiles),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "AgRS2F9AVvDq"
   },
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return {\"C\":0,\"A\":1,\"M\":2}[row[\"type_signal\"]]\n",
    "\n",
    "df[\"num_class\"] =df.apply(f, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MoeHi_gvST3W"
   },
   "outputs": [],
   "source": [
    "df = df.query(\"muscle=='BB'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "4Zc_4AzmrQ3s"
   },
   "outputs": [],
   "source": [
    "X = df['signal'].tolist()\n",
    "Y = df['num_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "NYc4-mxsrLpm"
   },
   "outputs": [],
   "source": [
    "X=X[170:]\n",
    "Y=Y[170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "aH0VoR_UE3yR"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262134,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_noise_1 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_2 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_3 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_4 = np.random.normal(0,1,len(X[0]))\n",
    "np.shape(random_noise_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "C0CR1uU2XRKo"
   },
   "outputs": [],
   "source": [
    "data = [*X]\n",
    "#data, np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1220, 262134)\n"
     ]
    }
   ],
   "source": [
    "data  += list(map(lambda x : x + random_noise_1, X))\n",
    "data  += list(map(lambda x : x + random_noise_2, X))\n",
    "data  += list(map(lambda x : x + random_noise_3, X))\n",
    "#data  += list(map(lambda x : x + random_noise_4, X))\n",
    "print(np.asarray(data).shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "n-GIqksRfZRm"
   },
   "outputs": [],
   "source": [
    "del  als,normal,myopathie,alsfiles,normalfiles,myopathiefiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Blrv7OFwUm4c"
   },
   "outputs": [],
   "source": [
    "data = scale_data_standard(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Bcr4HAHp421F"
   },
   "outputs": [],
   "source": [
    "last_index_normal = len(Y) - 1 - Y[::-1].index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "dmru4zsF421H"
   },
   "outputs": [],
   "source": [
    "last_index_als = len(Y) - 1 - Y[::-1].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "9tVZ_pi5421I"
   },
   "outputs": [],
   "source": [
    "last_index_myopathie = len(Y) - 1 - Y[::-1].index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "swCxixoS421I"
   },
   "outputs": [],
   "source": [
    "windowed_normal = len(windowing_fun(X[:last_index_normal+1],10000))\n",
    "windowed_als = len(windowing_fun(X[last_index_normal+1:last_index_als+1],10000))\n",
    "windowed_myopathie = len(windowing_fun(X[last_index_als+1:],10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "GvWbyRyg421I"
   },
   "outputs": [],
   "source": [
    "Y = [0]*(windowed_normal)+[1]*(windowed_als)+[2]*(windowed_myopathie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "GTZzqak7rFWV"
   },
   "outputs": [],
   "source": [
    "Y  = Y*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "r_VgwyYfYWnt"
   },
   "outputs": [],
   "source": [
    "X = windowing_fun(data,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "BpKYgn3EkgsU"
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3B8PeUZaeeQC"
   },
   "outputs": [],
   "source": [
    "X = scale_data_standard(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Q1h0Nh9nlim8"
   },
   "outputs": [],
   "source": [
    "tensors_list = gen_tensors_list(X,(1,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LAQNPWwyHK7g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30451, 1, 10000), (1269, 1, 10000))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( tensors_list, Y, test_size=0.04,random_state=20)\n",
    "np.shape(X_train), np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Conv2D(#of filters, filters size, activation function)\n",
    "    #in keras for the first layer we always need to mention the input shape\n",
    "    Conv1D(64, 3, activation = 'relu', padding =\"same\", input_shape = (1,10000)), \n",
    "    \n",
    "    #MaxPooling2D(filter size stride and pad can also be added)\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #LAYER2\n",
    "    Conv1D(32, 3, activation = 'relu', padding =\"same\"),\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #FLATTEN\n",
    "    Flatten(),\n",
    "    \n",
    "    #FC Layers:\n",
    "    \n",
    "    #LAYER3\n",
    "    #Dense : fully connected  Dense(#neurons, activation function )\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    #LAYER4\n",
    "    Dense(3, activation = 'softmax'),\n",
    "    \n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_text = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "238/238 [==============================] - 35s 129ms/step - loss: 1.0502 - accuracy: 0.4479\n",
      "Epoch 2/50\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.7240 - accuracy: 0.6681\n",
      "Epoch 3/50\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.4572 - accuracy: 0.8081\n",
      "Epoch 4/50\n",
      "238/238 [==============================] - 29s 124ms/step - loss: 0.3180 - accuracy: 0.8739\n",
      "Epoch 5/50\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.2233 - accuracy: 0.9168\n",
      "Epoch 6/50\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.1889 - accuracy: 0.9296\n",
      "Epoch 7/50\n",
      "238/238 [==============================] - 30s 124ms/step - loss: 0.1371 - accuracy: 0.9482\n",
      "Epoch 8/50\n",
      "238/238 [==============================] - 32s 136ms/step - loss: 0.1356 - accuracy: 0.9516\n",
      "Epoch 9/50\n",
      "238/238 [==============================] - 31s 130ms/step - loss: 0.1140 - accuracy: 0.9587\n",
      "Epoch 10/50\n",
      "238/238 [==============================] - 32s 134ms/step - loss: 0.1086 - accuracy: 0.9621\n",
      "Epoch 11/50\n",
      "238/238 [==============================] - 31s 130ms/step - loss: 0.0794 - accuracy: 0.9704\n",
      "Epoch 12/50\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0776 - accuracy: 0.9712\n",
      "Epoch 13/50\n",
      "238/238 [==============================] - 29s 124ms/step - loss: 0.0907 - accuracy: 0.9673\n",
      "Epoch 14/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0742 - accuracy: 0.9735\n",
      "Epoch 15/50\n",
      "238/238 [==============================] - 31s 128ms/step - loss: 0.0548 - accuracy: 0.9795\n",
      "Epoch 16/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0630 - accuracy: 0.9772\n",
      "Epoch 17/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0676 - accuracy: 0.9762\n",
      "Epoch 18/50\n",
      "238/238 [==============================] - 29s 124ms/step - loss: 0.0554 - accuracy: 0.9807\n",
      "Epoch 19/50\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0649 - accuracy: 0.9773\n",
      "Epoch 20/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0470 - accuracy: 0.9839\n",
      "Epoch 21/50\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0508 - accuracy: 0.9818\n",
      "Epoch 22/50\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0484 - accuracy: 0.9832\n",
      "Epoch 23/50\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0337 - accuracy: 0.9871\n",
      "Epoch 24/50\n",
      "238/238 [==============================] - 29s 124ms/step - loss: 0.0681 - accuracy: 0.9776\n",
      "Epoch 25/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0391 - accuracy: 0.9861\n",
      "Epoch 26/50\n",
      "238/238 [==============================] - 30s 124ms/step - loss: 0.0387 - accuracy: 0.9873\n",
      "Epoch 27/50\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0572 - accuracy: 0.9810\n",
      "Epoch 28/50\n",
      "238/238 [==============================] - 29s 124ms/step - loss: 0.0395 - accuracy: 0.9864\n",
      "Epoch 29/50\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0288 - accuracy: 0.9893\n",
      "Epoch 30/50\n",
      "238/238 [==============================] - 30s 126ms/step - loss: 0.0453 - accuracy: 0.9841\n",
      "Epoch 31/50\n",
      "238/238 [==============================] - 37s 155ms/step - loss: 0.0256 - accuracy: 0.9913\n",
      "Epoch 32/50\n",
      "238/238 [==============================] - 34s 141ms/step - loss: 0.0553 - accuracy: 0.9819\n",
      "Epoch 33/50\n",
      "238/238 [==============================] - 34s 143ms/step - loss: 0.0450 - accuracy: 0.9846\n",
      "Epoch 34/50\n",
      "238/238 [==============================] - 31s 130ms/step - loss: 0.0215 - accuracy: 0.9923\n",
      "Epoch 35/50\n",
      "238/238 [==============================] - 30s 128ms/step - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 36/50\n",
      "238/238 [==============================] - 30s 128ms/step - loss: 0.0431 - accuracy: 0.9856\n",
      "Epoch 37/50\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0481 - accuracy: 0.9838\n",
      "Epoch 38/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0277 - accuracy: 0.9903\n",
      "Epoch 39/50\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0286 - accuracy: 0.9906\n",
      "Epoch 40/50\n",
      "238/238 [==============================] - 29s 124ms/step - loss: 0.0260 - accuracy: 0.9910\n",
      "Epoch 41/50\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0459 - accuracy: 0.9855\n",
      "Epoch 42/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0302 - accuracy: 0.9895\n",
      "Epoch 43/50\n",
      "238/238 [==============================] - 30s 126ms/step - loss: 0.0264 - accuracy: 0.9908\n",
      "Epoch 44/50\n",
      "238/238 [==============================] - 30s 125ms/step - loss: 0.0178 - accuracy: 0.9931\n",
      "Epoch 45/50\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0296 - accuracy: 0.9901\n",
      "Epoch 46/50\n",
      "238/238 [==============================] - 30s 124ms/step - loss: 0.0642 - accuracy: 0.9808\n",
      "Epoch 47/50\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 48/50\n",
      "238/238 [==============================] - 30s 124ms/step - loss: 0.0179 - accuracy: 0.9934\n",
      "Epoch 49/50\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 50/50\n",
      "238/238 [==============================] - 30s 124ms/step - loss: 0.0321 - accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e36b1eb700>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs =50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 0.1380 - accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.asarray(X_test),np.asarray (y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12412), started 4:22:36 ago. (Use '!kill 12412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-705284c63f26a513\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-705284c63f26a513\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    \n",
    "    x = np.asarray(X_train)  ,\n",
    "    y= np.asarray(y_train) ,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(np.asarray(X_test),np.asarray (y_test) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcBPGVe5mc3z"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lVVOd4Enim8"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQl97_0NpBXX"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53pvhyxLpwia"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D_score.json', 'w+') as file:\n",
    "\n",
    "    json.dump(score, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFSDYnlvIrnb"
   },
   "outputs": [],
   "source": [
    "model= tf.keras.models.load_model(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathie\"}[i] for i in np.argmax(y_pred,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathie\"}[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=np.argmax(y_pred,axis=1)).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = [\"Normal\",\"Neuropathie\"], \n",
    "                     columns = [\"Normal\",\"Neuropathie\"])\n",
    "\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
