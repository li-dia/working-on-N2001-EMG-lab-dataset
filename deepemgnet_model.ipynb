{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2m-VDw7J1u4K"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import  keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,scale\n",
    "from skimage.measure import block_reduce\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8Rwb_WUh105H"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"data\"].transpose()  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['data'].transpose() # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['data'].transpose() #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lgHV-6wU12n5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_data_minmax(data):\n",
    "#type of scaler that scales the minimum and maximum values to be 0 and 1 respectively. \n",
    "    scaler = MinMaxScaler()\n",
    "#fit_transform() then it will calculate the mean(μ) and standard deviation(σ) of the feature F at a time it will transform the data points of the feature F.    \n",
    "    normalized_data =scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bcIEKXLjciKr"
   },
   "outputs": [],
   "source": [
    "def scale_data_standard(data):\n",
    "    scaled_data = scale(data,axis=1)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I_QR6IDs14Dm"
   },
   "outputs": [],
   "source": [
    "def gen_tensors_list(data,dim):\n",
    "    dataset  = list()\n",
    "    for i in range (len(data)):\n",
    "        arg = tf.convert_to_tensor(data[i], dtype=tf.float32)\n",
    "        arg = tf.reshape(arg,dim)\n",
    "        dataset.append(arg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gaSw9KLt15zX"
   },
   "outputs": [],
   "source": [
    "def windowing_fun(data,window_size=1000,overlap=100):\n",
    "    windowed_data = [data[j][i : i + window_size] for j in range(0,len(data)) for i in range(0, len(data[j]), window_size-overlap)]\n",
    "    final_data = [windowed_data[i] for i in range(len(windowed_data)) if len(windowed_data[i]) == window_size ]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zKAC9ocbn33R"
   },
   "outputs": [],
   "source": [
    "def load_file_names():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"files\"]  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['files'] # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['files'] #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CEcbdDJD36Ro"
   },
   "outputs": [],
   "source": [
    "def generate_dataframe(data,files):\n",
    "    df = pd.DataFrame([], columns=['type_signal',\"num_personne\",\"muscle\",\"num_enregistrement\",\"signal\"])\n",
    "    windowed_data = [{\"signal\": data[j],\"type_signal\":files[0][j][0][5],\"num_personne\": files[0][j][0][6:8],\"muscle\": files[0][j][0][8:10],\"num_enregistrement\":files[0][j][0][10:12] } for j in range(0,len(data)) ]\n",
    "    final_data = pd.DataFrame(windowed_data)\n",
    "    #df =df.append(final_data, ignore_index=True)\n",
    "    #df =pd.concat([df, final_data])\n",
    "    df = pd.concat([df, final_data], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "22ZQdg5FViHH"
   },
   "outputs": [],
   "source": [
    "als, normal , myopathy = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "70ffS0nSn3u9"
   },
   "outputs": [],
   "source": [
    "alsfiles,normalfiles,myopathyfiles = load_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m3v-unfnVKTq"
   },
   "outputs": [],
   "source": [
    "df = generate_dataframe(np.vstack((normal,als,myopathy)),np.concatenate((normalfiles,alsfiles,myopathyfiles),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AgRS2F9AVvDq"
   },
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return {\"C\":0,\"A\":1,\"M\":2}[row[\"type_signal\"]]\n",
    "\n",
    "df[\"num_class\"] =df.apply(f, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MoeHi_gvST3W"
   },
   "outputs": [],
   "source": [
    "df = df.query(\"muscle=='BB'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4Zc_4AzmrQ3s"
   },
   "outputs": [],
   "source": [
    "X = df['signal'].tolist()\n",
    "Y = df['num_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NYc4-mxsrLpm"
   },
   "outputs": [],
   "source": [
    "X=X[170:]\n",
    "Y=Y[170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aH0VoR_UE3yR"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262134,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_noise_1 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_2 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_3 = np.random.normal(0,1,len(X[0]))\n",
    "np.shape(random_noise_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "C0CR1uU2XRKo"
   },
   "outputs": [],
   "source": [
    "data = [*X]\n",
    "#data, np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1220, 262134)\n"
     ]
    }
   ],
   "source": [
    "data  += list(map(lambda x : x + random_noise_1, X))\n",
    "data  += list(map(lambda x : x + random_noise_2, X))\n",
    "data  += list(map(lambda x : x + random_noise_3, X))\n",
    "print(np.asarray(data).shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n-GIqksRfZRm"
   },
   "outputs": [],
   "source": [
    "del  als,normal,myopathy,alsfiles,normalfiles,myopathyfiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#print(data.type)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#print(data.type)\n",
    "print(data.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Blrv7OFwUm4c"
   },
   "outputs": [],
   "source": [
    "data = scale_data_standard(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Bcr4HAHp421F"
   },
   "outputs": [],
   "source": [
    "last_index_normal = len(Y) - 1 - Y[::-1].index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dmru4zsF421H"
   },
   "outputs": [],
   "source": [
    "last_index_als = len(Y) - 1 - Y[::-1].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9tVZ_pi5421I"
   },
   "outputs": [],
   "source": [
    "last_index_myopathy = len(Y) - 1 - Y[::-1].index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "swCxixoS421I"
   },
   "outputs": [],
   "source": [
    "windowed_normal = len(windowing_fun(X[:last_index_normal+1],10000))\n",
    "windowed_als = len(windowing_fun(X[last_index_normal+1:last_index_als+1],10000))\n",
    "windowed_myopathy = len(windowing_fun(X[last_index_als+1:],10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GvWbyRyg421I"
   },
   "outputs": [],
   "source": [
    "Y = [0]*(windowed_normal)+[1]*(windowed_als)+[2]*(windowed_myopathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GTZzqak7rFWV"
   },
   "outputs": [],
   "source": [
    "Y  = Y*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "r_VgwyYfYWnt"
   },
   "outputs": [],
   "source": [
    "X = windowing_fun(data,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BpKYgn3EkgsU"
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3B8PeUZaeeQC"
   },
   "outputs": [],
   "source": [
    "X = scale_data_standard(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Q1h0Nh9nlim8"
   },
   "outputs": [],
   "source": [
    "tensors_list = gen_tensors_list(X,(1,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LAQNPWwyHK7g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30451, 1, 10000), (1269, 1, 10000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( tensors_list, Y, test_size=0.04,random_state=20)\n",
    "np.shape(X_train), np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Conv2D(#of filters, filters size, activation function)\n",
    "    #in keras for the first layer we always need to mention the input shape\n",
    "    Conv1D(64, 3, activation = 'relu', padding =\"same\", input_shape = (1,10000)), \n",
    "    \n",
    "    #MaxPooling2D(filter size stride and pad can also be added)\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #LAYER2\n",
    "    Conv1D(32, 3, activation = 'relu', padding =\"same\"), #inc filter size and stride\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #FLATTEN\n",
    "    Flatten(),\n",
    "    \n",
    "    #FC Layers:\n",
    "    \n",
    "    #LAYER3\n",
    "    #Dense : fully connected  Dense(#neurons, activation function )\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    #LAYER4\n",
    "    Dense(3, activation = 'softmax'),\n",
    "    \n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_text = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "238/238 [==============================] - 35s 131ms/step - loss: 1.0439 - accuracy: 0.4585\n",
      "Epoch 2/60\n",
      "238/238 [==============================] - 31s 132ms/step - loss: 0.7352 - accuracy: 0.6769\n",
      "Epoch 3/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.4515 - accuracy: 0.8197\n",
      "Epoch 4/60\n",
      "238/238 [==============================] - 36s 151ms/step - loss: 0.2851 - accuracy: 0.8907\n",
      "Epoch 5/60\n",
      "238/238 [==============================] - 42s 176ms/step - loss: 0.2153 - accuracy: 0.9204\n",
      "Epoch 6/60\n",
      "238/238 [==============================] - 40s 167ms/step - loss: 0.1505 - accuracy: 0.9458\n",
      "Epoch 7/60\n",
      "238/238 [==============================] - 43s 179ms/step - loss: 0.1144 - accuracy: 0.9590\n",
      "Epoch 8/60\n",
      "238/238 [==============================] - 41s 171ms/step - loss: 0.1142 - accuracy: 0.9595\n",
      "Epoch 9/60\n",
      "238/238 [==============================] - 37s 155ms/step - loss: 0.0990 - accuracy: 0.9657\n",
      "Epoch 10/60\n",
      "238/238 [==============================] - 35s 148ms/step - loss: 0.0849 - accuracy: 0.9716\n",
      "Epoch 11/60\n",
      "238/238 [==============================] - 36s 152ms/step - loss: 0.0836 - accuracy: 0.9722\n",
      "Epoch 12/60\n",
      "238/238 [==============================] - 38s 162ms/step - loss: 0.0690 - accuracy: 0.9775\n",
      "Epoch 13/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0583 - accuracy: 0.9797\n",
      "Epoch 14/60\n",
      "238/238 [==============================] - 37s 157ms/step - loss: 0.0598 - accuracy: 0.9794\n",
      "Epoch 15/60\n",
      "238/238 [==============================] - 40s 169ms/step - loss: 0.0610 - accuracy: 0.9799\n",
      "Epoch 16/60\n",
      "238/238 [==============================] - 42s 175ms/step - loss: 0.0558 - accuracy: 0.9810\n",
      "Epoch 17/60\n",
      "238/238 [==============================] - 41s 171ms/step - loss: 0.0419 - accuracy: 0.9855\n",
      "Epoch 18/60\n",
      "238/238 [==============================] - 32s 134ms/step - loss: 0.0604 - accuracy: 0.9807\n",
      "Epoch 19/60\n",
      "238/238 [==============================] - 32s 136ms/step - loss: 0.0476 - accuracy: 0.9849\n",
      "Epoch 20/60\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0477 - accuracy: 0.9844\n",
      "Epoch 21/60\n",
      "238/238 [==============================] - 28s 116ms/step - loss: 0.0393 - accuracy: 0.9865\n",
      "Epoch 22/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0390 - accuracy: 0.9876\n",
      "Epoch 23/60\n",
      "238/238 [==============================] - 26s 108ms/step - loss: 0.0529 - accuracy: 0.9833\n",
      "Epoch 24/60\n",
      "238/238 [==============================] - 26s 111ms/step - loss: 0.0460 - accuracy: 0.9851\n",
      "Epoch 25/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 26/60\n",
      "238/238 [==============================] - 28s 116ms/step - loss: 0.0246 - accuracy: 0.9913\n",
      "Epoch 27/60\n",
      "238/238 [==============================] - 30s 126ms/step - loss: 0.0572 - accuracy: 0.9821\n",
      "Epoch 28/60\n",
      "238/238 [==============================] - 27s 114ms/step - loss: 0.0406 - accuracy: 0.9867\n",
      "Epoch 29/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0242 - accuracy: 0.9916\n",
      "Epoch 30/60\n",
      "238/238 [==============================] - 28s 117ms/step - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 31/60\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0454 - accuracy: 0.9866\n",
      "Epoch 32/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0418 - accuracy: 0.9865\n",
      "Epoch 33/60\n",
      "238/238 [==============================] - 32s 132ms/step - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 34/60\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0173 - accuracy: 0.9932\n",
      "Epoch 35/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0410 - accuracy: 0.9876\n",
      "Epoch 36/60\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0368 - accuracy: 0.9883\n",
      "Epoch 37/60\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 38/60\n",
      "238/238 [==============================] - 27s 113ms/step - loss: 0.0267 - accuracy: 0.9913\n",
      "Epoch 39/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 40/60\n",
      "238/238 [==============================] - 32s 135ms/step - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 41/60\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "238/238 [==============================] - 27s 115ms/step - loss: 0.0432 - accuracy: 0.9859\n",
      "Epoch 43/60\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.0230 - accuracy: 0.9918\n",
      "Epoch 44/60\n",
      "238/238 [==============================] - 28s 118ms/step - loss: 0.0112 - accuracy: 0.9959\n",
      "Epoch 45/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0295 - accuracy: 0.9911\n",
      "Epoch 46/60\n",
      "238/238 [==============================] - 32s 133ms/step - loss: 0.0374 - accuracy: 0.9884\n",
      "Epoch 47/60\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0262 - accuracy: 0.9921\n",
      "Epoch 48/60\n",
      "238/238 [==============================] - 26s 109ms/step - loss: 0.0209 - accuracy: 0.9931\n",
      "Epoch 49/60\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 50/60\n",
      "238/238 [==============================] - 31s 130ms/step - loss: 0.0339 - accuracy: 0.9898\n",
      "Epoch 51/60\n",
      "238/238 [==============================] - 32s 136ms/step - loss: 0.0307 - accuracy: 0.9911\n",
      "Epoch 52/60\n",
      "238/238 [==============================] - 32s 133ms/step - loss: 0.0161 - accuracy: 0.9943\n",
      "Epoch 53/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0175 - accuracy: 0.9950\n",
      "Epoch 54/60\n",
      "238/238 [==============================] - 33s 137ms/step - loss: 0.0267 - accuracy: 0.9909\n",
      "Epoch 55/60\n",
      "238/238 [==============================] - 26s 108ms/step - loss: 0.0324 - accuracy: 0.9896\n",
      "Epoch 56/60\n",
      "238/238 [==============================] - 26s 107ms/step - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 57/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 58/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0338 - accuracy: 0.9893\n",
      "Epoch 59/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0224 - accuracy: 0.9923\n",
      "Epoch 60/60\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0150 - accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1daf0a55be0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs =60, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.asarray(X_test),np.asarray (y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12412), started 3 days, 6:53:55 ago. (Use '!kill 12412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-77758f704aa92e99\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-77758f704aa92e99\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9927WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 50s 109ms/step - loss: 0.0300 - accuracy: 0.9927 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
      "Epoch 2/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 48s 111ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0549 - val_accuracy: 0.9908\n",
      "Epoch 3/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9922WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 41s 94ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 0.0309 - val_accuracy: 0.9918\n",
      "Epoch 4/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9947WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9939WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 43s 99ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.0336 - val_accuracy: 0.9924\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9932WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 46s 108ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.0293 - val_accuracy: 0.9931\n",
      "Epoch 7/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9961WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 42s 98ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0282 - val_accuracy: 0.9938\n",
      "Epoch 8/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9970WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 94ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.0505 - val_accuracy: 0.9905\n",
      "Epoch 9/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9929WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 0.0265 - val_accuracy: 0.9928\n",
      "Epoch 10/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9933WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 41s 95ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0324 - val_accuracy: 0.9924\n",
      "Epoch 11/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9918WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 93ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0454 - val_accuracy: 0.9905\n",
      "Epoch 12/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9939WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 92ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.0460 - val_accuracy: 0.9892\n",
      "Epoch 13/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 41s 97ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0407 - val_accuracy: 0.9934\n",
      "Epoch 14/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9963WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 42s 98ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0393 - val_accuracy: 0.9915\n",
      "Epoch 15/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9943WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 93ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0411 - val_accuracy: 0.9924\n",
      "Epoch 16/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9910WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 0.0552 - val_accuracy: 0.9875\n",
      "Epoch 17/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9937WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 92ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0262 - val_accuracy: 0.9941\n",
      "Epoch 18/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9948WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 94ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
      "Epoch 19/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9963WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0323 - val_accuracy: 0.9931\n",
      "Epoch 20/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9941WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 90ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0478 - val_accuracy: 0.9885\n",
      "Epoch 21/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0354 - val_accuracy: 0.9934\n",
      "Epoch 22/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9964WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0458 - val_accuracy: 0.9911\n",
      "Epoch 23/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9928WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 90ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.0551 - val_accuracy: 0.9908\n",
      "Epoch 24/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9937WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 90ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.0737 - val_accuracy: 0.9885\n",
      "Epoch 25/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9939WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 38s 89ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0354 - val_accuracy: 0.9931\n",
      "Epoch 26/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9961WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 36s 84ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0315 - val_accuracy: 0.9938\n",
      "Epoch 27/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 36s 83ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0304 - val_accuracy: 0.9947\n",
      "Epoch 28/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9975WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 40s 94ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0478 - val_accuracy: 0.9918\n",
      "Epoch 29/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9930WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 39s 91ms/step - loss: 0.0284 - accuracy: 0.9930 - val_loss: 0.0545 - val_accuracy: 0.9849\n",
      "Epoch 30/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9934WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 37s 86ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0353 - val_accuracy: 0.9905\n",
      "Epoch 31/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9975WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 28s 65ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0280 - val_accuracy: 0.9938\n",
      "Epoch 32/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 28s 66ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.0299 - val_accuracy: 0.9938\n",
      "Epoch 33/50\n",
      "  5/429 [..............................] - ETA: 29s - loss: 0.0131 - accuracy: 0.9937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [ tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlogdir),tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_sparse_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,patience \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m ,min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)]\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trying this to be able to use tensorboard\n",
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    \n",
    "    x = np.asarray(X_train)  ,\n",
    "    y= np.asarray(y_train) ,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.asarray(X_test),np.asarray (y_test) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "UcBPGVe5mc3z"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "9lVVOd4Enim8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12412), started 3 days, 4:53:53 ago. (Use '!kill 12412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1fc750e0e4c30173\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1fc750e0e4c30173\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "jQl97_0NpBXX"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "53pvhyxLpwia"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D_score.json', 'w+') as file:\n",
    "\n",
    "    json.dump(score, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jFSDYnlvIrnb"
   },
   "outputs": [],
   "source": [
    "model= tf.keras.models.load_model(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in np.argmax(y_pred,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 3), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m con_mat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mconfusion_matrix(labels\u001b[38;5;241m=\u001b[39my_test, predictions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y_pred,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m con_mat_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(con_mat\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m con_mat\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis], decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m con_mat_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon_mat_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m figure \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(con_mat_df, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3, 3), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=np.argmax(y_pred,axis=1)).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = [\"Normal\",\"Neuropathie\"], \n",
    "                     columns = [\"Normal\",\"Neuropathie\"])\n",
    "\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
