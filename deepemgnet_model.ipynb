{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2m-VDw7J1u4K"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import  keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,scale\n",
    "from skimage.measure import block_reduce\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8Rwb_WUh105H"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"data\"].transpose()  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['data'].transpose() # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['data'].transpose() #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lgHV-6wU12n5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_data_minmax(data):\n",
    "#type of scaler that scales the minimum and maximum values to be 0 and 1 respectively. \n",
    "    scaler = MinMaxScaler()\n",
    "#fit_transform() then it will calculate the mean(μ) and standard deviation(σ) of the feature F at a time it will transform the data points of the feature F.    \n",
    "    normalized_data =scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bcIEKXLjciKr"
   },
   "outputs": [],
   "source": [
    "def scale_data_standard(data):\n",
    "    scaled_data = scale(data,axis=1)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I_QR6IDs14Dm"
   },
   "outputs": [],
   "source": [
    "def gen_tensors_list(data,dim):\n",
    "    dataset  = list()\n",
    "    for i in range (len(data)):\n",
    "        arg = tf.convert_to_tensor(data[i], dtype=tf.float32)\n",
    "        arg = tf.reshape(arg,dim)\n",
    "        dataset.append(arg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gaSw9KLt15zX"
   },
   "outputs": [],
   "source": [
    "def windowing_fun(data,window_size=1000,overlap=100):\n",
    "    windowed_data = [data[j][i : i + window_size] for j in range(0,len(data)) for i in range(0, len(data[j]), window_size-overlap)]\n",
    "    final_data = [windowed_data[i] for i in range(len(windowed_data)) if len(windowed_data[i]) == window_size ]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zKAC9ocbn33R"
   },
   "outputs": [],
   "source": [
    "def load_file_names():\n",
    "    als = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/ALS.mat',)[\"files\"]  #(262134, 321)\n",
    "    normal = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/normal.mat')['files'] # (262134, 270) \n",
    "    myopathy = scipy.io.loadmat('C:/Users/lenovo/OneDrive/Documents/drive-download-20230214T190624Z-001/myopathie.mat')['files'] #(262134, 315)\n",
    "    return als,normal,myopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CEcbdDJD36Ro"
   },
   "outputs": [],
   "source": [
    "def generate_dataframe(data,files):\n",
    "    df = pd.DataFrame([], columns=['type_signal',\"num_personne\",\"muscle\",\"num_enregistrement\",\"signal\"])\n",
    "    windowed_data = [{\"signal\": data[j],\"type_signal\":files[0][j][0][5],\"num_personne\": files[0][j][0][6:8],\"muscle\": files[0][j][0][8:10],\"num_enregistrement\":files[0][j][0][10:12] } for j in range(0,len(data)) ]\n",
    "    final_data = pd.DataFrame(windowed_data)\n",
    "    #df =df.append(final_data, ignore_index=True)\n",
    "    #df =pd.concat([df, final_data])\n",
    "    df = pd.concat([df, final_data], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "22ZQdg5FViHH"
   },
   "outputs": [],
   "source": [
    "als, normal , myopathy = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "70ffS0nSn3u9"
   },
   "outputs": [],
   "source": [
    "alsfiles,normalfiles,myopathyfiles = load_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m3v-unfnVKTq"
   },
   "outputs": [],
   "source": [
    "df = generate_dataframe(np.vstack((normal,als,myopathy)),np.concatenate((normalfiles,alsfiles,myopathyfiles),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AgRS2F9AVvDq"
   },
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return {\"C\":0,\"A\":1,\"M\":2}[row[\"type_signal\"]]\n",
    "\n",
    "df[\"num_class\"] =df.apply(f, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MoeHi_gvST3W"
   },
   "outputs": [],
   "source": [
    "df = df.query(\"muscle=='BB'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4Zc_4AzmrQ3s"
   },
   "outputs": [],
   "source": [
    "X = df['signal'].tolist()\n",
    "Y = df['num_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NYc4-mxsrLpm"
   },
   "outputs": [],
   "source": [
    "X=X[170:]\n",
    "Y=Y[170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aH0VoR_UE3yR"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262134,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_noise_1 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_2 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_3 = np.random.normal(0,1,len(X[0]))\n",
    "random_noise_4 = np.random.normal(0,1,len(X[0]))\n",
    "np.shape(random_noise_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "C0CR1uU2XRKo"
   },
   "outputs": [],
   "source": [
    "data = [*X]\n",
    "#data, np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1220, 262134)\n"
     ]
    }
   ],
   "source": [
    "data  += list(map(lambda x : x + random_noise_1, X))\n",
    "data  += list(map(lambda x : x + random_noise_2, X))\n",
    "data  += list(map(lambda x : x + random_noise_3, X))\n",
    "#data  += list(map(lambda x : x + random_noise_4, X))\n",
    "print(np.asarray(data).shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n-GIqksRfZRm"
   },
   "outputs": [],
   "source": [
    "del  als,normal,myopathy,alsfiles,normalfiles,myopathyfiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Blrv7OFwUm4c"
   },
   "outputs": [],
   "source": [
    "data = scale_data_standard(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Bcr4HAHp421F"
   },
   "outputs": [],
   "source": [
    "last_index_normal = len(Y) - 1 - Y[::-1].index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dmru4zsF421H"
   },
   "outputs": [],
   "source": [
    "last_index_als = len(Y) - 1 - Y[::-1].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9tVZ_pi5421I"
   },
   "outputs": [],
   "source": [
    "last_index_myopathy = len(Y) - 1 - Y[::-1].index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "swCxixoS421I"
   },
   "outputs": [],
   "source": [
    "windowed_normal = len(windowing_fun(X[:last_index_normal+1],10000))\n",
    "windowed_als = len(windowing_fun(X[last_index_normal+1:last_index_als+1],10000))\n",
    "windowed_myopathy = len(windowing_fun(X[last_index_als+1:],10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GvWbyRyg421I"
   },
   "outputs": [],
   "source": [
    "Y = [0]*(windowed_normal)+[1]*(windowed_als)+[2]*(windowed_myopathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GTZzqak7rFWV"
   },
   "outputs": [],
   "source": [
    "Y  = Y*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "r_VgwyYfYWnt"
   },
   "outputs": [],
   "source": [
    "X = windowing_fun(data,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BpKYgn3EkgsU"
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3B8PeUZaeeQC"
   },
   "outputs": [],
   "source": [
    "X = scale_data_standard(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Q1h0Nh9nlim8"
   },
   "outputs": [],
   "source": [
    "tensors_list = gen_tensors_list(X,(1,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LAQNPWwyHK7g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30451, 1, 10000), (1269, 1, 10000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( tensors_list, Y, test_size=0.04,random_state=20)\n",
    "np.shape(X_train), np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Conv2D(#of filters, filters size, activation function)\n",
    "    #in keras for the first layer we always need to mention the input shape\n",
    "    Conv1D(64, 3, activation = 'relu', padding =\"same\", input_shape = (1,10000)), \n",
    "    \n",
    "    #MaxPooling2D(filter size stride and pad can also be added)\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #LAYER2\n",
    "    Conv1D(32, 3, activation = 'relu', padding =\"same\"),\n",
    "    MaxPooling1D(2, strides = 2, padding =\"same\"),\n",
    "    \n",
    "    #FLATTEN\n",
    "    Flatten(),\n",
    "    \n",
    "    #FC Layers:\n",
    "    \n",
    "    #LAYER3\n",
    "    #Dense : fully connected  Dense(#neurons, activation function )\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    #LAYER4\n",
    "    Dense(3, activation = 'softmax'),\n",
    "    \n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_text = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "238/238 [==============================] - 35s 131ms/step - loss: 1.0439 - accuracy: 0.4585\n",
      "Epoch 2/60\n",
      "238/238 [==============================] - 31s 132ms/step - loss: 0.7352 - accuracy: 0.6769\n",
      "Epoch 3/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.4515 - accuracy: 0.8197\n",
      "Epoch 4/60\n",
      "238/238 [==============================] - 36s 151ms/step - loss: 0.2851 - accuracy: 0.8907\n",
      "Epoch 5/60\n",
      "238/238 [==============================] - 42s 176ms/step - loss: 0.2153 - accuracy: 0.9204\n",
      "Epoch 6/60\n",
      "238/238 [==============================] - 40s 167ms/step - loss: 0.1505 - accuracy: 0.9458\n",
      "Epoch 7/60\n",
      "238/238 [==============================] - 43s 179ms/step - loss: 0.1144 - accuracy: 0.9590\n",
      "Epoch 8/60\n",
      "238/238 [==============================] - 41s 171ms/step - loss: 0.1142 - accuracy: 0.9595\n",
      "Epoch 9/60\n",
      "238/238 [==============================] - 37s 155ms/step - loss: 0.0990 - accuracy: 0.9657\n",
      "Epoch 10/60\n",
      "238/238 [==============================] - 35s 148ms/step - loss: 0.0849 - accuracy: 0.9716\n",
      "Epoch 11/60\n",
      "238/238 [==============================] - 36s 152ms/step - loss: 0.0836 - accuracy: 0.9722\n",
      "Epoch 12/60\n",
      "238/238 [==============================] - 38s 162ms/step - loss: 0.0690 - accuracy: 0.9775\n",
      "Epoch 13/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0583 - accuracy: 0.9797\n",
      "Epoch 14/60\n",
      "238/238 [==============================] - 37s 157ms/step - loss: 0.0598 - accuracy: 0.9794\n",
      "Epoch 15/60\n",
      "238/238 [==============================] - 40s 169ms/step - loss: 0.0610 - accuracy: 0.9799\n",
      "Epoch 16/60\n",
      "238/238 [==============================] - 42s 175ms/step - loss: 0.0558 - accuracy: 0.9810\n",
      "Epoch 17/60\n",
      "238/238 [==============================] - 41s 171ms/step - loss: 0.0419 - accuracy: 0.9855\n",
      "Epoch 18/60\n",
      "238/238 [==============================] - 32s 134ms/step - loss: 0.0604 - accuracy: 0.9807\n",
      "Epoch 19/60\n",
      "238/238 [==============================] - 32s 136ms/step - loss: 0.0476 - accuracy: 0.9849\n",
      "Epoch 20/60\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0477 - accuracy: 0.9844\n",
      "Epoch 21/60\n",
      "238/238 [==============================] - 28s 116ms/step - loss: 0.0393 - accuracy: 0.9865\n",
      "Epoch 22/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0390 - accuracy: 0.9876\n",
      "Epoch 23/60\n",
      "238/238 [==============================] - 26s 108ms/step - loss: 0.0529 - accuracy: 0.9833\n",
      "Epoch 24/60\n",
      "238/238 [==============================] - 26s 111ms/step - loss: 0.0460 - accuracy: 0.9851\n",
      "Epoch 25/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 26/60\n",
      "238/238 [==============================] - 28s 116ms/step - loss: 0.0246 - accuracy: 0.9913\n",
      "Epoch 27/60\n",
      "238/238 [==============================] - 30s 126ms/step - loss: 0.0572 - accuracy: 0.9821\n",
      "Epoch 28/60\n",
      "238/238 [==============================] - 27s 114ms/step - loss: 0.0406 - accuracy: 0.9867\n",
      "Epoch 29/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0242 - accuracy: 0.9916\n",
      "Epoch 30/60\n",
      "238/238 [==============================] - 28s 117ms/step - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 31/60\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0454 - accuracy: 0.9866\n",
      "Epoch 32/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0418 - accuracy: 0.9865\n",
      "Epoch 33/60\n",
      "238/238 [==============================] - 32s 132ms/step - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 34/60\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0173 - accuracy: 0.9932\n",
      "Epoch 35/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0410 - accuracy: 0.9876\n",
      "Epoch 36/60\n",
      "238/238 [==============================] - 29s 122ms/step - loss: 0.0368 - accuracy: 0.9883\n",
      "Epoch 37/60\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 38/60\n",
      "238/238 [==============================] - 27s 113ms/step - loss: 0.0267 - accuracy: 0.9913\n",
      "Epoch 39/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 40/60\n",
      "238/238 [==============================] - 32s 135ms/step - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 41/60\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "238/238 [==============================] - 27s 115ms/step - loss: 0.0432 - accuracy: 0.9859\n",
      "Epoch 43/60\n",
      "238/238 [==============================] - 29s 121ms/step - loss: 0.0230 - accuracy: 0.9918\n",
      "Epoch 44/60\n",
      "238/238 [==============================] - 28s 118ms/step - loss: 0.0112 - accuracy: 0.9959\n",
      "Epoch 45/60\n",
      "238/238 [==============================] - 28s 119ms/step - loss: 0.0295 - accuracy: 0.9911\n",
      "Epoch 46/60\n",
      "238/238 [==============================] - 32s 133ms/step - loss: 0.0374 - accuracy: 0.9884\n",
      "Epoch 47/60\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0262 - accuracy: 0.9921\n",
      "Epoch 48/60\n",
      "238/238 [==============================] - 26s 109ms/step - loss: 0.0209 - accuracy: 0.9931\n",
      "Epoch 49/60\n",
      "238/238 [==============================] - 30s 127ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 50/60\n",
      "238/238 [==============================] - 31s 130ms/step - loss: 0.0339 - accuracy: 0.9898\n",
      "Epoch 51/60\n",
      "238/238 [==============================] - 32s 136ms/step - loss: 0.0307 - accuracy: 0.9911\n",
      "Epoch 52/60\n",
      "238/238 [==============================] - 32s 133ms/step - loss: 0.0161 - accuracy: 0.9943\n",
      "Epoch 53/60\n",
      "238/238 [==============================] - 31s 129ms/step - loss: 0.0175 - accuracy: 0.9950\n",
      "Epoch 54/60\n",
      "238/238 [==============================] - 33s 137ms/step - loss: 0.0267 - accuracy: 0.9909\n",
      "Epoch 55/60\n",
      "238/238 [==============================] - 26s 108ms/step - loss: 0.0324 - accuracy: 0.9896\n",
      "Epoch 56/60\n",
      "238/238 [==============================] - 26s 107ms/step - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 57/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 58/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0338 - accuracy: 0.9893\n",
      "Epoch 59/60\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0224 - accuracy: 0.9923\n",
      "Epoch 60/60\n",
      "238/238 [==============================] - 29s 123ms/step - loss: 0.0150 - accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1daf0a55be0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs =60, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.asarray(X_test),np.asarray (y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b93779e84ee05f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b93779e84ee05f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=/tmp  --port=6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12412), started 3 days, 4:31:27 ago. (Use '!kill 12412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-93781b0e627736da\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-93781b0e627736da\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9858WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 29s 64ms/step - loss: 0.0531 - accuracy: 0.9858 - val_loss: 0.0208 - val_accuracy: 0.9921\n",
      "Epoch 2/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9925WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 27s 63ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0270 - val_accuracy: 0.9895\n",
      "Epoch 3/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9933WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 28s 66ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0238 - val_accuracy: 0.9908\n",
      "Epoch 4/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9898WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 62ms/step - loss: 0.0375 - accuracy: 0.9898 - val_loss: 0.0463 - val_accuracy: 0.9846\n",
      "Epoch 5/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9900WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 27s 63ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.0212 - val_accuracy: 0.9911\n",
      "Epoch 6/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9907WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 28s 66ms/step - loss: 0.0306 - accuracy: 0.9907 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 7/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9921WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 31s 72ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0388 - val_accuracy: 0.9892\n",
      "Epoch 8/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9886WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 27s 63ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.0155 - val_accuracy: 0.9928\n",
      "Epoch 9/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9944WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 30s 70ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0365 - val_accuracy: 0.9885\n",
      "Epoch 10/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9876WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 37s 85ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0238 - val_accuracy: 0.9911\n",
      "Epoch 11/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9916WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 32s 74ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0254 - val_accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9941WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0246 - val_accuracy: 0.9902\n",
      "Epoch 13/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9885WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 30s 69ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0233 - val_accuracy: 0.9928\n",
      "Epoch 14/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9932WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0182 - val_accuracy: 0.9931\n",
      "Epoch 15/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9893WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0248 - val_accuracy: 0.9911\n",
      "Epoch 16/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9912WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 61ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0571 - val_accuracy: 0.9806\n",
      "Epoch 17/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9899WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 61ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.0267 - val_accuracy: 0.9885\n",
      "Epoch 18/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9923WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 29s 68ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0092 - val_accuracy: 0.9957\n",
      "Epoch 19/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9939WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 30s 69ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.0225 - val_accuracy: 0.9885\n",
      "Epoch 20/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9922WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 29s 68ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0211 - val_accuracy: 0.9918\n",
      "Epoch 21/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9896WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 28s 65ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.0173 - val_accuracy: 0.9911\n",
      "Epoch 22/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9935WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 28s 65ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 0.0085 - val_accuracy: 0.9951\n",
      "Epoch 23/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9923WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0555 - val_accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9874WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.0200 - val_accuracy: 0.9915\n",
      "Epoch 25/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9952WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0151 - val_accuracy: 0.9931\n",
      "Epoch 26/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9957WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.0124 - val_accuracy: 0.9938\n",
      "Epoch 27/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9926WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.0718 - val_accuracy: 0.9793\n",
      "Epoch 28/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9879WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 0.0185 - val_accuracy: 0.9931\n",
      "Epoch 29/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9927WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.0213 - val_accuracy: 0.9928\n",
      "Epoch 30/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9949WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0234 - val_accuracy: 0.9908\n",
      "Epoch 31/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9930WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0242 - val_accuracy: 0.9918\n",
      "Epoch 32/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9928WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 27s 62ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
      "Epoch 33/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9928WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0144 - val_accuracy: 0.9947\n",
      "Epoch 34/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9909WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0271 - val_accuracy: 0.9915\n",
      "Epoch 35/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9942WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0202 - val_accuracy: 0.9938\n",
      "Epoch 36/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9941WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.0184 - val_accuracy: 0.9934\n",
      "Epoch 37/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9926WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0446 - val_accuracy: 0.9872\n",
      "Epoch 38/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9938WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 39/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9912WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 60ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.0373 - val_accuracy: 0.9885\n",
      "Epoch 40/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9927WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 26s 59ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0409 - val_accuracy: 0.9921\n",
      "Epoch 41/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9957WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 27s 62ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.0287 - val_accuracy: 0.9941\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/429 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0470 - val_accuracy: 0.9882\n",
      "Epoch 43/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9907WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 58ms/step - loss: 0.0351 - accuracy: 0.9907 - val_loss: 0.0421 - val_accuracy: 0.9872\n",
      "Epoch 44/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9936WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0301 - val_accuracy: 0.9931\n",
      "Epoch 45/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9936WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 59ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.0935 - val_accuracy: 0.9836\n",
      "Epoch 46/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9901WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 58ms/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.0261 - val_accuracy: 0.9924\n",
      "Epoch 47/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9956WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 57ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0232 - val_accuracy: 0.9947\n",
      "Epoch 48/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9957WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 25s 57ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0491 - val_accuracy: 0.9872\n",
      "Epoch 49/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9901WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 24s 57ms/step - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.0188 - val_accuracy: 0.9941\n",
      "Epoch 50/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "429/429 [==============================] - 24s 57ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0349 - val_accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "logdir = \"drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=logdir),tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience =60 ,min_delta=1e-3)]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    \n",
    "    x = np.asarray(X_train)  ,\n",
    "    y= np.asarray(y_train) ,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.asarray(X_test),np.asarray (y_test) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "UcBPGVe5mc3z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "9lVVOd4Enim8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12412), started 3 days, 4:53:53 ago. (Use '!kill 12412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1fc750e0e4c30173\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1fc750e0e4c30173\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir drive/MyDrive/PFE_TENSORBOARD_DATA/augmentation0/CNN1D/logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "jQl97_0NpBXX"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "53pvhyxLpwia"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D_score.json', 'w+') as file:\n",
    "\n",
    "    json.dump(score, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "jFSDYnlvIrnb"
   },
   "outputs": [],
   "source": [
    "model= tf.keras.models.load_model(\"/content/drive/MyDrive/PFE_RESULTS_DATA/augmentation0/scaling/CNN1D/CNN1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in np.argmax(y_pred,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_labels = [{0:\"Normal\",1:\"Neuropathie\",2:\"Myopathy\"}[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 3), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m con_mat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mconfusion_matrix(labels\u001b[38;5;241m=\u001b[39my_test, predictions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y_pred,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m con_mat_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(con_mat\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m con_mat\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis], decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m con_mat_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon_mat_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeuropathie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m figure \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(con_mat_df, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3, 3), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=np.argmax(y_pred,axis=1)).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = [\"Normal\",\"Neuropathie\"], \n",
    "                     columns = [\"Normal\",\"Neuropathie\"])\n",
    "\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
